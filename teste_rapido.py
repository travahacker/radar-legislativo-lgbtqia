"""
Teste rÃ¡pido do modelo e funÃ§Ãµes principais
"""
from transformers import pipeline
import torch

print("ğŸ³ï¸â€ğŸŒˆ Testando Radar Social LGBTQIA+ V2.1...\n")

# Teste 1: Carregar modelo
print("1ï¸âƒ£ Carregando modelo...")
try:
    classifier = pipeline(
        "text-classification",
        model="Veronyka/radar-social-lgbtqia-v2.1",
        device=-1  # CPU
    )
    print("   âœ… Modelo carregado com sucesso!\n")
except Exception as e:
    print(f"   âŒ Erro: {e}\n")
    exit(1)

# Teste 2: AnÃ¡lise de texto conhecido (desfavorÃ¡vel)
print("2ï¸âƒ£ Testando com PL desfavorÃ¡vel conhecida...")
texto_desfavoravel = "ProÃ­be o uso de banheiro por pessoas de sexo biologicamente diferente do designado"
resultado = classifier(texto_desfavoravel, truncation=True, max_length=256)
label = resultado[0]['label']
score = resultado[0]['score']
score_odio = 1 - score if label != 'HATE' else score
print(f"   Label: {label}")
print(f"   Score original: {score:.2%}")
print(f"   Score de Ã³dio: {score_odio:.2%}")
print(f"   ClassificaÃ§Ã£o: {'DESFAVORÃVEL' if score_odio >= 0.5 else 'REVISÃƒO' if score_odio >= 0.3 else 'FAVORÃVEL'}")
print("   âœ… Teste concluÃ­do!\n")

# Teste 3: AnÃ¡lise de texto favorÃ¡vel
print("3ï¸âƒ£ Testando com PL favorÃ¡vel conhecida...")
texto_favoravel = "Criminaliza a discriminaÃ§Ã£o por orientaÃ§Ã£o sexual e identidade de gÃªnero"
resultado = classifier(texto_favoravel, truncation=True, max_length=256)
label = resultado[0]['label']
score = resultado[0]['score']
score_odio = 1 - score if label != 'HATE' else score
print(f"   Label: {label}")
print(f"   Score original: {score:.2%}")
print(f"   Score de Ã³dio: {score_odio:.2%}")
print(f"   ClassificaÃ§Ã£o: {'DESFAVORÃVEL' if score_odio >= 0.5 else 'REVISÃƒO' if score_odio >= 0.3 else 'FAVORÃVEL'}")
print("   âœ… Teste concluÃ­do!\n")

# Teste 4: Ementa real do resultados1.md
print("4ï¸âƒ£ Testando com ementa real...")
ementa_real = "ProÃ­be a divulgaÃ§Ã£o de 'ideologia de gÃªnero' em escolas pÃºblicas e privadas (altera o ECA)"
resultado = classifier(ementa_real, truncation=True, max_length=256)
label = resultado[0]['label']
score = resultado[0]['score']
score_odio = 1 - score if label != 'HATE' else score
print(f"   Ementa: '{ementa_real}'")
print(f"   Score de Ã³dio: {score_odio:.2%}")
print(f"   ClassificaÃ§Ã£o: {'DESFAVORÃVEL' if score_odio >= 0.5 else 'REVISÃƒO' if score_odio >= 0.3 else 'FAVORÃVEL'}")
print("   âœ… Teste concluÃ­do!\n")

print("ğŸ‰ Todos os testes passaram! O modelo estÃ¡ funcionando.")

