# üè≥Ô∏è‚Äçüåà Plano Revisado: QuiterIA Transfeminista

## üìä Diagn√≥stico do Problema Atual

### Por que os resultados n√£o foram bons?

1. **Dom√≠nio diferente**: Radar Social treinado em Instagram, n√£o em legisla√ß√£o
2. **Linguagem jur√≠dica**: Formal, t√©cnica, sem g√≠rias de √≥dio expl√≠citas
3. **Contexto ausente**: Modelo n√£o entende implica√ß√µes pol√≠ticas, hist√≥ricas
4. **Vi√©s de g√™nero**: Modelo AzMina focado em mulheres cis, n√£o em toda comunidade LGBTQIA+

### Dados dispon√≠veis

- ‚úÖ **37 PLs anotadas** (18 favor√°veis, 19 desfavor√°veis) - arquivo `resultadoscompilados.md`
- ‚úÖ **Modelo AzMina**: `azmina/ia-feminista-bert-posicao` (Favor√°vel/Desfavor√°vel a direitos de mulheres)
- ‚úÖ **Modelo Radar Social**: `Veronyka/radar-social-lgbtqia-v2.1` (√ìdio LGBTQIA+ em redes sociais)
- ‚ö†Ô∏è **Limita√ß√£o**: Dataset pequeno para treinamento direto (ideal: 100-200 PLs)

---

## üéØ Plano em 3 Fases

### FASE 1: Ensemble H√≠brido (2-3 semanas)

**Objetivo**: Combinar os dois modelos existentes de forma inteligente

#### 1.1 An√°lise por M√∫ltiplos Sinais

Criar um sistema que combina:

```python
# Pseudo-c√≥digo do ensemble
def classificar_pl_ensemble(pl_texto):
    # Sinal 1: Radar Social (detec√ß√£o de √≥dio)
    score_odio = radar_social(pl_texto)
    
    # Sinal 2: AzMina (direitos de mulheres - proxy para transfeminismo)
    score_mulheres = azmina(pl_texto)
    
    # Sinal 3: Palavras-chave espec√≠ficas LGBTQIA+
    keywords_pro = extract_keywords_pro(pl_texto)
    keywords_anti = extract_keywords_anti(pl_texto)
    
    # Sinal 4: Padr√µes lingu√≠sticos legislativos
    padrao_restritivo = detectar_padroes_restritivos(pl_texto)
    
    # Combinar com pesos aprendidos ou heur√≠sticos
    score_final = (
        0.40 * normalizar(score_odio) +           # 40% - detec√ß√£o de √≥dio
        0.30 * normalizar(score_mulheres) +        # 30% - perspectiva feminista
        0.20 * (keywords_anti - keywords_pro) +    # 20% - keywords
        0.10 * padrao_restritivo                    # 10% - padr√µes
    )
    
    return classificar(score_final)
```

#### 1.2 Keywords LGBTQIA+ Espec√≠ficas

**Keywords Favor√°veis:**
- `identidade de g√™nero`, `orienta√ß√£o sexual`, `LGBTQIA+`, `diversidade sexual`
- `nome social`, `autodetermina√ß√£o`, `direitos humanos`
- `discrimina√ß√£o`, `viol√™ncia`, `prote√ß√£o` (em contexto positivo)

**Keywords Desfavor√°veis:**
- `sexo biol√≥gico`, `sexo de nascimento`, `ideologia de g√™nero`
- `pro√≠be`, `veda`, `restringe` + termos LGBTQIA+
- `valores familiares`, `prote√ß√£o √† inf√¢ncia` (em contexto anti-LGBTQIA+)

#### 1.3 Padr√µes Legislativos

Detectar estruturas t√≠picas de PLs desfavor√°veis:
- "Define X como Y" onde Y √© crit√©rio biol√≥gico exclusivo
- "Pro√≠be o ensino de..."
- "Veda o uso de... por pessoas de..."

### FASE 2: Fine-tuning Supervisionado (1-2 meses)

**Objetivo**: Treinar modelo espec√≠fico para PLs com os dados anotados

#### 2.1 Expandir Dataset (CR√çTICO)

**Atualmente**: 30 PLs (MUITO POUCO para treinamento)

**Necess√°rio**: 
- **M√≠nimo ideal**: 200-300 PLs anotadas
- **M√≠nimo vi√°vel**: 100 PLs (50/50)
- **Considerando augmentation**: 50 PLs com t√©cnicas de data augmentation

**Como coletar mais PLs:**
1. Buscar PLs similares nos sites do Congresso
2. Organiza√ß√µes LGBTQIA+ podem ter mapeamentos
3. Tentar encontrar datasets p√∫blicos de an√°lise legislativa

#### 2.2 Estrat√©gia de Treinamento

**Op√ß√£o A: Fine-tune do Radar Social**
```python
# Come√ßar do Radar Social (j√° entende LGBTfobia)
model = AutoModelForSequenceClassification.from_pretrained(
    "Veronyka/radar-social-lgbtqia-v2.1",
    num_labels=2  # FAVOR√ÅVEL / DESFAVOR√ÅVEL
)
# Treinar com PLs anotadas
```

**Op√ß√£o B: Multi-task Learning**
```python
# Treinar modelo que faz duas tarefas:
# 1. Detec√ß√£o de √≥dio (Radar Social)
# 2. Classifica√ß√£o legislativa (AzMina-style)
```

**Op√ß√£o C: Continua√ß√£o do AzMina**
```python
# Adaptar modelo AzMina (j√° entende legisla√ß√£o)
# Expandir de "direitos mulheres" para "direitos LGBTQIA+"
model = AutoModelForSequenceClassification.from_pretrained(
    "azmina/ia-feminista-bert-posicao",
    num_labels=2
)
```

**Recomenda√ß√£o**: Op√ß√£o A (Fine-tune do Radar Social) porque:
- J√° entende LGBTfobia
- Base portuguesa (Tupi-BERT)
- F√°cil de adaptar

#### 2.3 Data Augmentation

Para aumentar dataset pequeno:
- **Par√°frase**: Reescrever ementas mantendo sentido
- **Nega√ß√£o controlada**: Criar exemplos adversos
- **Sintaxe variada**: Mudar ordem, estruturas

#### 2.4 Valida√ß√£o Estruturada

- **Treino**: 70% (com augment)
- **Valida√ß√£o**: 15%
- **Teste**: 15%
- **Cross-validation** se dataset < 100 PLs

### FASE 3: Fine-tuning Transfer Learning (Futuro)

**Objetivo**: Modelo final especializado

#### 3.1 Ensemble Ensino-Aprendizagem

Treinar modelo final que aprende dos ensemblers:
1. Ensemble atual (Fase 1) gera "labels suaves"
2. Modelo de fine-tuning aprende desses labels + anota√ß√µes humanas
3. Itera√ß√£o at√© converg√™ncia

#### 3.2 Expans√£o Cont√≠nua

- Sistema de feedback: usu√°rios corrigem classifica√ß√µes
- Active learning: identificar PLs que precisam anota√ß√£o
- Re-treinar periodicamente com novos dados

---

## üìã Checklist de Implementa√ß√£o

### Fase 1 (Ensemble) - EM ANDAMENTO

- [x] Unificar datasets (`resultadoscompilados.md` - 39 PLs)
- [x] Implementar fun√ß√£o de ensemble combinando 4 sinais
- [x] Criar lista inicial de keywords favor√°veis/desfavor√°veis
- [x] Implementar detec√ß√£o de padr√µes legislativos
- [x] Testar ensemble nas 39 PLs anotadas
- [x] Ajustar pesos do ensemble baseado em resultados (keywords: 35%, padr√µes: 20%)
- [x] Calcular m√©tricas: Precision, Recall, F1 por classe
- [x] Expandir lista de keywords baseado em casos de erro
- [ ] Validar em casos edge (PL 6583, PL 106, PL 906)
- [ ] Criar interface mostrando contribui√ß√£o de cada sinal

### Fase 2 (Fine-tuning) - Quando tiver 50+ PLs

- [ ] Expandir dataset para pelo menos 50 PLs anotadas
- [ ] Explorar data augmentation
- [ ] Escolher estrat√©gia de fine-tuning (A, B ou C)
- [ ] Configurar ambiente de treinamento (GPU se poss√≠vel)
- [ ] Treinar modelo piloto
- [ ] Validar em conjunto separado
- [ ] Comparar com ensemble (baseline)

### Fase 3 (Otimiza√ß√£o) - Depois do MVP

- [ ] Implementar sistema de feedback
- [ ] Active learning para identificar casos dif√≠ceis
- [ ] Pipeline de re-treinamento autom√°tico
- [ ] Documenta√ß√£o completa de limita√ß√µes

---

## üéØ M√©tricas de Sucesso

### Fase 1 (Ensemble)

**M√≠nimo vi√°vel:**
- Accuracy >= 70% no conjunto de 30 PLs
- Recall >= 85% para classe DESFAVOR√ÅVEL (priorit√°rio!)
- Precision >= 65% para DESFAVOR√ÅVEL

**Ideal:**
- Accuracy >= 80%
- F1-score >= 75%
- Concord√¢ncia com anota√ß√£o humana >= 85%

### Fase 2 (Fine-tuning)

**M√≠nimo vi√°vel:**
- Melhoria de pelo menos 5pp sobre ensemble
- Recall DESFAVOR√ÅVEL >= 90%
- F1-score >= 80%

---

## ‚ö†Ô∏è Riscos e Mitiga√ß√µes

| Risco | Impacto | Mitiga√ß√£o |
|-------|---------|-----------|
| Dataset muito pequeno | Alto | Data augmentation + buscar mais PLs |
| Overfitting em treinamento | M√©dio | Valida√ß√£o rigorosa + early stopping |
| Vi√©s nos dados de treinamento | Alto | Revisar anota√ß√µes com equipe LGBTQIA+ |
| Modelo n√£o generalizar | M√©dio | Testar com PLs fora do dataset original |
| Falsos positivos em linguagem t√©cnica | Alto | Threshold conservador + revis√£o humana sempre |

---

## üìö Recursos Necess√°rios

### Humanos
- **Anotadores LGBTQIA+**: Validar e expandir dataset
- **Especialistas jur√≠dicos**: Revisar contexto legislativo
- **Engenheiros ML**: Treinamento e valida√ß√£o

### T√©cnicos
- **GPU**: Para treinamento eficiente (Google Colab Pro ou similar)
- **Storage**: Para dataset e checkpoints
- **Computation**: ~2-4 horas de GPU para fine-tuning

---

## üöÄ Pr√≥ximos Passos Imediatos

1. **Implementar ensemble h√≠brido** (Fase 1)
2. **Testar nos 30 PLs** anotadas
3. **Ajustar pesos** baseado em resultados
4. **Documentar erros** e casos de edge
5. **Planejar expans√£o** do dataset para Fase 2

---

## üí° Alternativas se Fine-tuning N√£o For Vi√°vel

Se n√£o conseguirmos coletar dados suficientes:

1. **Usar ensemble apenas** como ferramenta de triagem
2. **Focar em explicabilidade**: Por que classificou assim? (SHAP, LIME)
3. **Sistema h√≠brido humano+IA**: IA sugere, humano decide sempre
4. **Documenta√ß√£o de limita√ß√µes**: Ser transparente sobre o que funciona e o que n√£o funciona

---

**√öltima atualiza√ß√£o**: 2025-01-XX
**Status**: Fase 1 - Em planejamento

